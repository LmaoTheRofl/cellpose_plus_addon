{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torchvision.transforms import ToTensor, Compose, ConvertImageDtype\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Data_manager import MaskRCNNDataset, mask_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ede16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Image.open('../data/Hesperidine_u87m6_5_10_g_neg/u87m6_5_k_g/labels/7.png')\n",
    "mask.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../data/Hesperidine_u87m6_5_10_g_neg/u87m6_5_k_g6.tif')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1936d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = '../data/Control_u87m6_5_g_neg/u87m6_5_k_g/labels'\n",
    "transform = Compose([ToTensor(), ConvertImageDtype(torch.float)])\n",
    "mask_files = sorted(os.listdir(labels_dir), key=lambda x: int(x.split('.')[0]))\n",
    "masks = []\n",
    "for mf in mask_files:\n",
    "    mask_path = os.path.join(labels_dir, mf)\n",
    "    mask = Image.open(mask_path) #.convert('L')\n",
    "    # mask.show()\n",
    "    masks.append(mask)\n",
    "mask_tensors = []\n",
    "boxes = []\n",
    "for mask in masks:\n",
    "    mask_tensor = transform(mask) \n",
    "    mask_tensor = (mask_tensor > 0).float() \n",
    "            \n",
    "    if mask_tensor.sum() == 0: \n",
    "        continue\n",
    "    y_indices, x_indices = torch.nonzero(mask_tensor[0] > 0, as_tuple=True)\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "    boxes.append([x_min.item(), y_min.item(), x_max.item() + 1, y_max.item() + 1])  # [xmin, ymin, xmax, ymax]\n",
    "            \n",
    "    mask_tensors.append(mask_tensor)  \n",
    "\n",
    "\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd1d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "H, W = mask_tensors[0].shape[1], mask_tensors[0].shape[2] \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "black_bg = np.zeros((H, W, 3))  \n",
    "ax.imshow(black_bg) \n",
    "\n",
    "for box in boxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    rect = Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"bounding boxes\")\n",
    "ax.axis('off')  \n",
    "plt.show()\n",
    "\n",
    "all_masks_sum = torch.sum(torch.stack(mask_tensors), dim=0).squeeze(0).numpy()  \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(all_masks_sum, cmap='gray')  \n",
    "ax.set_title(\"Все маски\")\n",
    "ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa13b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = '../data/Hesperidine_u87m6_5_10_g_neg'\n",
    "train_dataset = MaskRCNNDataset(train_root_dir)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=False, collate_fn = mask_collate_fn)\n",
    "\n",
    "valid_root_dir = '../data/Control_u87m6_5_g_neg'\n",
    "valid_dataset = MaskRCNNDataset(valid_root_dir)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn = mask_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63642f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_epochs = 25\n",
    "num_classes = 3\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights='DEFAULT')\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=hidden_layer, dim_reduced=hidden_layer, num_classes=num_classes)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546aaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b592486",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, targets = batch\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        # Обучение\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += losses.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Валидация\n",
    "    model.train() \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, targets = batch\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            val_loss += losses.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bfaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses = [1.4756587400580898, 0.8217112801291726, 0.7165061163179802, 0.6636899131717104, 0.645452978033008, 0.6519268913702532, 0.6376912873802763, 0.642753415035479, 0.6498193650534658, 0.6433846661538789, 0.6306558341690989, 0.6258593472567472, 0.6405845627640233, 0.6416629607027228, 0.6549802187717322, 0.6428265923803503, 0.6410629731236082, 0.6430845459302267, 0.6496207605708729, 0.6444839844197938, 0.6442109635381987, 0.6433917807810234, 0.6434001778111313, 0.6393992268677914, 0.6442327987064015]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_losses = [0.8105309685071309, 0.795963176091512, 0.6757086396217347, 0.6683217088381449, 0.6554469664891561, 0.6486938198407491, 0.6587509830792745, 0.6582305034001669, 0.6447886904080709, 0.6463489532470703, 0.6598559737205505, 0.6401790380477905, 0.6402595996856689, 0.6464001218477885, 0.6533783992131551, 0.6518285115559895, 0.6619373202323914, 0.6613343159357706, 0.650204849243164, 0.6555777589480082, 0.6415329456329346, 0.6399871587753296, 0.6489090164502461, 0.6553272644678751, 0.653343923886617]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09730f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, num_epochs + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Val Loss': val_losses\n",
    "})\n",
    "fig = px.line(df, x='Epoch', y=['Train Loss', 'Val Loss'], title='Training and Validation Loss Curves')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0ab7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../trained/test_mask_rcnn.pth')\n",
    "print(\"Модель сохранена как test_mask_rcnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d3db7a",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(image, prediction, threshold=0.5):\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()  \n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    for box, label, score, mask in zip(prediction['boxes'], prediction['labels'], prediction['scores'], prediction['masks']):\n",
    "        if score > threshold:\n",
    "\n",
    "            rect = patches.Rectangle((box[0].item(), box[1].item()), box[2].item() - box[0].item(), box[3].item() - box[1].item(),\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            # ax.text(box[0].item(), box[1].item() - 5, f'{label}',\n",
    "            #         color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n",
    "            \n",
    "            mask = mask[0].cpu().numpy()\n",
    "            mask = np.ma.masked_where(mask <= 0.5, mask)\n",
    "            ax.imshow(mask, alpha=1.0, cmap='jet')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir = '../data/Control_u87m6_5_g_neg/u87m6_5_k_g/labels'\n",
    "transform = Compose([ToTensor(), ConvertImageDtype(torch.float)])\n",
    "mask_files = sorted(os.listdir(labels_dir), key=lambda x: int(x.split('.')[0]))\n",
    "masks = []\n",
    "for mf in mask_files:\n",
    "    mask_path = os.path.join(labels_dir, mf)\n",
    "    mask = Image.open(mask_path) #.convert('L')\n",
    "    # mask.show()\n",
    "    masks.append(mask)\n",
    "mask_tensors = []\n",
    "boxes = []\n",
    "for mask in masks:\n",
    "    mask_tensor = transform(mask) \n",
    "    mask_tensor = (mask_tensor > 0).float() \n",
    "            \n",
    "    if mask_tensor.sum() == 0: \n",
    "        continue\n",
    "    y_indices, x_indices = torch.nonzero(mask_tensor[0] > 0, as_tuple=True)\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "    boxes.append([x_min.item(), y_min.item(), x_max.item() + 1, y_max.item() + 1])  # [xmin, ymin, xmax, ymax]\n",
    "            \n",
    "    mask_tensors.append(mask_tensor)  \n",
    "\n",
    "\n",
    "print(len(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = mask_tensors[0].shape[1], mask_tensors[0].shape[2] \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "black_bg = np.zeros((H, W, 3))  \n",
    "ax.imshow(black_bg) \n",
    "\n",
    "for box in boxes:\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    rect = Rectangle((x_min, y_min), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_title(\"bounding boxes\")\n",
    "ax.axis('off')  \n",
    "plt.show()\n",
    "\n",
    "all_masks_sum = torch.sum(torch.stack(mask_tensors), dim=0).squeeze(0).numpy()  \n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "ax.imshow(all_masks_sum, cmap='gray')  \n",
    "ax.set_title(\"Все маски\")\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "device = 'cuda'\n",
    "num_classes = 3\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=None)  \n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=hidden_layer, dim_reduced=hidden_layer, num_classes=num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('../trained/test_mask_rcnn.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "img_path = '../data/Control_u87m6_5_g_neg/u87m6_5_k_g.tif'\n",
    "transform = Compose([ToTensor(), ConvertImageDtype(torch.float)])\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model([image_tensor])[0]\n",
    "\n",
    "visualize_prediction(image_tensor, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center_csv = os.path.join('../data/Hesperidine_u87m6_5_10_g_neg/u87m6_5_k_g/primary/u87m6_5_k_g_Center.csv')\n",
    "# size_roundness_csv = os.path.join('../data/Hesperidine_u87m6_5_10_g_neg/u87m6_5_k_g/primary/u87m6_5_k_g_size_roundness.csv')\n",
    "        \n",
    "# info = pd.concat([pd.read_csv(center_csv, names=['x', 'y']), pd.read_csv(size_roundness_csv, names=['size', 'roundness'])], axis = 1)\n",
    "# info['classes'] = info['size'].apply(lambda x: 1 if x <= 40 else 2)\n",
    "# info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
