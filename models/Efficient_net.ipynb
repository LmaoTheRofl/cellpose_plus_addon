{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72a410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(root)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as patches\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torchvision.transforms import ToTensor, Compose, ConvertImageDtype\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Data_manager import EfficientDataset, eff_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902af662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = efficientnet_b0(weights='DEFAULT').features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1280, 512, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, num_classes, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        feat = self.encoder(x)\n",
    "        out = self.decoder(feat)\n",
    "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca94513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_root_dir = '../data/Hesperidine_u87m6_5_10_g_neg'\n",
    "train_dataset = EfficientDataset(train_root_dir)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=False, collate_fn=eff_collate_fn)\n",
    "\n",
    "valid_root_dir = '../data/Control_u87m6_5_g_neg'\n",
    "valid_dataset = EfficientDataset(valid_root_dir)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=eff_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c52cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_epochs = 15\n",
    "num_classes = 3\n",
    "model = EfficientNet(num_classes=num_classes)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, targets = batch\n",
    "        images = images.to(device)\n",
    "        targets = [target.to(device) for target in targets]\n",
    "        # Обучение\n",
    "        preds = model(images)\n",
    "        targets_tensor = torch.stack(targets)\n",
    "        loss = criterion(preds, targets_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, targets = batch\n",
    "            images = images.to(device)\n",
    "            targets = [target.to(device) for target in targets]\n",
    "            preds = model(images)\n",
    "            targets_tensor = torch.stack(targets)\n",
    "            loss = criterion(preds, targets_tensor)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(valid_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Val Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366531ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, num_epochs + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Val Loss': val_losses\n",
    "})\n",
    "fig = px.line(df, x='Epoch', y=['Train Loss', 'Val Loss'], title='Training and Validation Loss Curves')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../trained/test_efficient.pth')\n",
    "print(\"Модель сохранена как test_efficient.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701aa645",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_prediction(image, prediction):\n",
    "\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()  \n",
    "    pred_mask = torch.argmax(prediction, dim=0).cpu().numpy()\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    masked = np.ma.masked_where(pred_mask == 0, pred_mask)\n",
    "    ax.imshow(masked, alpha=1.0, cmap='jet')  \n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
